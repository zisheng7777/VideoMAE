{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from timm.models import create_model\n",
    "import numpy as np\n",
    "# from csvdata import CSVMAE\n",
    "import utils\n",
    "import modeling_pretrain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 參數設定（手動設定，不需要 argparse）\n",
    "csv_folder = \"/mnt/d/mae/bigclassroom/foundation_dataset/456\"   # 輸入 CSV 檔案\n",
    "save_path = \"output_csv\"  # 結果輸出的資料夾\n",
    "model_path = \"ckpt_output_dir/checkpoint-1999.pth\"  # 模型檔案\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # 自動選擇 GPU 或 CPU\n",
    "model_name = \"pretrain_videomae_base_patch1_4\"  # 你的 VideoMAE 模型\n",
    "drop_path = 0.0  # Drop Path Rate   \n",
    "mask_ratio = 0.75  # 設定 Masking 比例 (例如 75%)\n",
    "num_frames = 16\n",
    "decoder_depth = 8\n",
    "patch_size = 1\n",
    "window_size = (num_frames // 2, 4, 4)  # (T, H, W)\n",
    "# 確保輸出資料夾存在\n",
    "Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "csv_files = sorted([f for f in os.listdir(csv_folder) if f.endswith(\".csv\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_mask = [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from masking_generator import TubeMaskingGenerator\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "class CSVMAETEST(Dataset):\n",
    "    def __init__(self, root_dir, num_frames=16, mask_ratio=0.75, window_size=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.num_frames = num_frames\n",
    "        self.window_size = window_size\n",
    "        self.mask_generator = TubeMaskingGenerator(window_size, mask_ratio=mask_ratio, custom_mask=custom_mask)\n",
    "\n",
    "        # 遞迴地獲取所有 CSV 檔案\n",
    "        self.file_paths = []\n",
    "        for subdir, _, files in os.walk(root_dir):\n",
    "            for file in files:\n",
    "                if file.endswith('.csv'):\n",
    "                    self.file_paths.append(os.path.join(subdir, file))\n",
    "\n",
    "        # 自訂排序函數: 先按類別名稱排序，再按數字時間戳排序\n",
    "        def extract_sort_key(path):\n",
    "            filename = os.path.basename(path)\n",
    "            match = re.match(r\"(.+?)_(\\d+)\\.csv\", filename)  # 擷取類別名稱 & 數字\n",
    "            if match:\n",
    "                category = match.group(1)  # 取得類別名稱 (如 1119-1in3out-mv-mc-mid)\n",
    "                time_value = int(match.group(2))  # 取得數字時間戳\n",
    "                return (category, time_value)\n",
    "            return (filename, 0)  # 若無法匹配則放最後\n",
    "\n",
    "        # 排序後按類別分組\n",
    "        self.file_paths.sort(key=extract_sort_key)\n",
    "        self.groups = defaultdict(list)  # 每個類別對應的 CSV 檔案\n",
    "        for path in self.file_paths:\n",
    "            category = extract_sort_key(path)[0]  # 取得類別名稱\n",
    "            self.groups[category].append(path)\n",
    "\n",
    "        # 預先切割成 num_frames 時間段，確保分組不重複\n",
    "        self.sequence_groups = []\n",
    "        for category, files in self.groups.items():\n",
    "            if len(files) >= num_frames:\n",
    "                for i in range(0, len(files) - num_frames + 1, num_frames):  # 修改這裡，使每次分組間隔num_frames\n",
    "                    self.sequence_groups.append(files[i: i + num_frames])\n",
    "\n",
    "        # 檢查是否有可用數據\n",
    "        if not self.sequence_groups:\n",
    "            raise ValueError(f\"CSV 檔案數量不足 {num_frames}，請檢查 `{root_dir}` 資料夾！\")\n",
    "\n",
    "        # 顯示前 5 組數據確認順序\n",
    "        print(\"= 加載的 CSV 時間序列組: (顯示前 5 組) =\")\n",
    "        for i, seq in enumerate(self.sequence_groups[:5]):\n",
    "            print(f\"組 {i+1}: {[os.path.basename(f) for f in seq]}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequence_groups)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_list = self.sequence_groups[idx]  # 取得對應的一組 num_frames CSV 檔案\n",
    "        frames = []\n",
    "        for csv_path in file_list:\n",
    "            data = np.genfromtxt(csv_path, delimiter=',')\n",
    "            frames.append(data)\n",
    "\n",
    "        frames = np.stack(frames)  # (T, H, W)\n",
    "\n",
    "        # 增加 Channel 維度 -> (C=1, T, H, W)\n",
    "        frames = np.expand_dims(frames, axis=0)\n",
    "        frames = torch.tensor(frames, dtype=torch.float32)\n",
    "\n",
    "        # 生成 mask\n",
    "        mask = self.mask_generator()\n",
    "\n",
    "        return (frames, mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= 加載的 CSV 時間序列組: (顯示前 5 組) =\n",
      "組 1: ['1119-1in3out-mv-mc-mid_5.csv', '1119-1in3out-mv-mc-mid_10.csv', '1119-1in3out-mv-mc-mid_15.csv', '1119-1in3out-mv-mc-mid_20.csv', '1119-1in3out-mv-mc-mid_25.csv', '1119-1in3out-mv-mc-mid_30.csv', '1119-1in3out-mv-mc-mid_35.csv', '1119-1in3out-mv-mc-mid_40.csv', '1119-1in3out-mv-mc-mid_45.csv', '1119-1in3out-mv-mc-mid_50.csv', '1119-1in3out-mv-mc-mid_55.csv', '1119-1in3out-mv-mc-mid_60.csv', '1119-1in3out-mv-mc-mid_65.csv', '1119-1in3out-mv-mc-mid_70.csv', '1119-1in3out-mv-mc-mid_75.csv', '1119-1in3out-mv-mc-mid_80.csv']\n",
      "組 2: ['1119-1in3out-mv-mc-mid_85.csv', '1119-1in3out-mv-mc-mid_90.csv', '1119-1in3out-mv-mc-mid_95.csv', '1119-1in3out-mv-mc-mid_100.csv', '1119-1in3out-mv-mc-mid_105.csv', '1119-1in3out-mv-mc-mid_110.csv', '1119-1in3out-mv-mc-mid_115.csv', '1119-1in3out-mv-mc-mid_120.csv', '1119-1in3out-mv-mc-mid_125.csv', '1119-1in3out-mv-mc-mid_130.csv', '1119-1in3out-mv-mc-mid_135.csv', '1119-1in3out-mv-mc-mid_140.csv', '1119-1in3out-mv-mc-mid_145.csv', '1119-1in3out-mv-mc-mid_150.csv', '1119-1in3out-mv-mc-mid_155.csv', '1119-1in3out-mv-mc-mid_160.csv']\n",
      "組 3: ['1119-1in3out-mv-mc-mid_165.csv', '1119-1in3out-mv-mc-mid_170.csv', '1119-1in3out-mv-mc-mid_175.csv', '1119-1in3out-mv-mc-mid_180.csv', '1119-1in3out-mv-mc-mid_185.csv', '1119-1in3out-mv-mc-mid_190.csv', '1119-1in3out-mv-mc-mid_195.csv', '1119-1in3out-mv-mc-mid_200.csv', '1119-1in3out-mv-mc-mid_205.csv', '1119-1in3out-mv-mc-mid_210.csv', '1119-1in3out-mv-mc-mid_215.csv', '1119-1in3out-mv-mc-mid_220.csv', '1119-1in3out-mv-mc-mid_225.csv', '1119-1in3out-mv-mc-mid_230.csv', '1119-1in3out-mv-mc-mid_235.csv', '1119-1in3out-mv-mc-mid_240.csv']\n",
      "組 4: ['1119-1in3out-mv-mc-mid_245.csv', '1119-1in3out-mv-mc-mid_250.csv', '1119-1in3out-mv-mc-mid_255.csv', '1119-1in3out-mv-mc-mid_260.csv', '1119-1in3out-mv-mc-mid_265.csv', '1119-1in3out-mv-mc-mid_270.csv', '1119-1in3out-mv-mc-mid_275.csv', '1119-1in3out-mv-mc-mid_280.csv', '1119-1in3out-mv-mc-mid_285.csv', '1119-1in3out-mv-mc-mid_290.csv', '1119-1in3out-mv-mc-mid_295.csv', '1119-1in3out-mv-mc-mid_300.csv', '1119-1in3out-mv-mc-mid_305.csv', '1119-1in3out-mv-mc-mid_310.csv', '1119-1in3out-mv-mc-mid_315.csv', '1119-1in3out-mv-mc-mid_320.csv']\n",
      "組 5: ['1119-1in3out-mv-mc-mid_325.csv', '1119-1in3out-mv-mc-mid_330.csv', '1119-1in3out-mv-mc-mid_335.csv', '1119-1in3out-mv-mc-mid_340.csv', '1119-1in3out-mv-mc-mid_345.csv', '1119-1in3out-mv-mc-mid_350.csv', '1119-1in3out-mv-mc-mid_355.csv', '1119-1in3out-mv-mc-mid_360.csv', '1119-1in3out-mv-mc-mid_365.csv', '1119-1in3out-mv-mc-mid_370.csv', '1119-1in3out-mv-mc-mid_375.csv', '1119-1in3out-mv-mc-mid_380.csv', '1119-1in3out-mv-mc-mid_385.csv', '1119-1in3out-mv-mc-mid_390.csv', '1119-1in3out-mv-mc-mid_395.csv', '1119-1in3out-mv-mc-mid_400.csv']\n",
      "Loading model: pretrain_videomae_base_patch1_4\n",
      "pretrain_videomae_base_patch1_4 is being executed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2535561/4187398625.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=\"cpu\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PretrainVisionTransformer(\n",
       "  (encoder): PretrainVisionTransformerEncoder(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv3d(1, 768, kernel_size=(2, 1, 1), stride=(2, 1, 1))\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0-11): 12 x Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (head): Identity()\n",
       "  )\n",
       "  (decoder): PretrainVisionTransformerDecoder(\n",
       "    (blocks): ModuleList(\n",
       "      (0-7): 8 x Block(\n",
       "        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "    (head): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       "  (encoder_to_decoder): Linear(in_features=768, out_features=512, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = CSVMAETEST(root_dir=csv_folder, num_frames=num_frames, mask_ratio=mask_ratio, window_size=window_size)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "print(f\"Loading model: {model_name}\")\n",
    "\n",
    "model = create_model(\n",
    "        model_name,\n",
    "        pretrained=False,\n",
    "        drop_path_rate=0,\n",
    "        drop_block_rate=None,\n",
    "        decoder_depth=decoder_depth,\n",
    "        use_checkpoint=model_path\n",
    "    )\n",
    "checkpoint = torch.load(model_path, map_location=\"cpu\")\n",
    "model.load_state_dict(checkpoint[\"model\"])\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_normalize(log_normalized_values):\n",
    "    # 將 0~1 的正規化數據反轉回 log 範圍，然後再轉回線性空間的原始範圍\n",
    "    original_min = 300\n",
    "    original_max = 1600\n",
    "    log_values = log_normalized_values * (np.log(original_max) - np.log(original_min)) + np.log(original_min)\n",
    "    original_values = np.exp(log_values)\n",
    "    return original_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for video 0: 0.002899080514907837\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 1: 0.0044289506040513515\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 2: 0.0023416648618876934\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for video 3: 0.0020556622184813023\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 4: 0.0028789681382477283\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 5: 0.002318082842975855\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 6: 0.002188839018344879\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 7: 0.0032433411106467247\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for video 8: 0.0024422649294137955\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 9: 0.0014716566074639559\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 10: 0.0016057101311162114\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 11: 0.0010196678340435028\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 12: 0.0008419518126174808\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for video 13: 0.0004488519625738263\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 14: 0.00038490607403218746\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 15: 0.001671662088483572\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 16: 0.0014508028980344534\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 17: 0.0008252931875176728\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for video 18: 0.0018800904508680105\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 19: 0.0006583036156371236\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 20: 0.004521622322499752\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 21: 0.0026586195454001427\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 22: 0.0014308742247521877\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for video 23: 0.0025491099804639816\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 24: 0.0010373072000220418\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 25: 0.0009260214865207672\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 26: 0.0007329643703997135\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 27: 0.0012101843021810055\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for video 28: 0.0012758761877194047\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 29: 0.0033207666128873825\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 30: 0.0020950494799762964\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 31: 0.00226253317669034\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 32: 0.0007531484588980675\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for video 33: 0.0007104355609044433\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 34: 0.001528094056993723\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 35: 0.003332449123263359\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 36: 0.0029773046262562275\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 37: 0.0004075428587384522\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for video 38: 0.0006841092254035175\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 39: 0.0008136228425428271\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 40: 0.0005859936936758459\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 41: 0.0009556381264701486\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 42: 0.0013937163166701794\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 43: 0.0008542629657313228\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "✅ 所有結果已合併儲存至 output_csv/final_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from einops import rearrange\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "final_df_list = []\n",
    "\n",
    "for idx, (videos, bool_masked_pos) in enumerate(dataloader):\n",
    "    videos = videos.to(device, non_blocking=True)\n",
    "    bool_masked_pos = bool_masked_pos.to(device, non_blocking=True).flatten(1).to(torch.bool)\n",
    "\n",
    "    # 進行推理\n",
    "    with torch.no_grad():\n",
    "        # Rearrange and process the frames\n",
    "        videos_patch = rearrange(videos, 'b c (t p0) (h p1) (w p2) -> b (t h w) (p0 p1 p2 c)',\n",
    "                                 p0=2, p1=patch_size, p2=patch_size)\n",
    "        B, _, C = videos_patch.shape\n",
    "\n",
    "        labels = videos_patch[bool_masked_pos].reshape(B, -1, C)\n",
    "        outputs = model(videos, bool_masked_pos)\n",
    "        loss = loss_func(input=outputs, target=labels)\n",
    "        print(f\"Loss for video {idx}: {loss.item()}\")\n",
    "\n",
    "    # 轉換為 NumPy 格式\n",
    "    outputs_np = outputs.cpu().detach().numpy().reshape(-1, 2)  # (N_mask, C)\n",
    "    mask_np = bool_masked_pos.cpu().detach().numpy().reshape(-1).astype(int)  # (N,)\n",
    "\n",
    "    # ✅ **即時儲存結果**（原本的方式）\n",
    "    output_list = [outputs_np]\n",
    "    mask_list = [mask_np]\n",
    "\n",
    "    df_outputs = pd.DataFrame(np.concatenate(output_list, axis=0))  # (N, C)\n",
    "    df_masks = pd.DataFrame(np.concatenate(mask_list, axis=0))  # (N,)\n",
    "\n",
    "    print(\"🔍 原始 mask 形狀:\", df_masks.shape)\n",
    "    print(\"🔍 原始 output 形狀:\", df_outputs.shape)\n",
    "\n",
    "    # **還原完整的感測器數據**\n",
    "    sensor_data = videos.cpu().detach().numpy().squeeze(0)  # (C=1, T, H, W) → (T, H, W)\n",
    "    sensor_data = sensor_data.reshape(num_frames, -1)  # 轉換為 (T, sensors)\n",
    "    # 保留一份原始感測器數據（反正規化前）\n",
    "    sensor_data_ori = sensor_data.copy()\n",
    "    sensor_data_ori = inverse_normalize(sensor_data_ori)\n",
    "\n",
    "    # **mask=1 的地方用 `df_outputs` 預測值替換**\n",
    "    predicted_values = df_outputs.to_numpy().reshape(num_frames, -1)  # (T, 預測的 sensor 值)\n",
    "    mask_reshaped = df_masks.to_numpy().reshape(-1, num_frames)  # (H × W, T) → (T, H × W)\n",
    "    mask_reshaped = np.tile(mask_reshaped, (2, 1))\n",
    "\n",
    "    print(predicted_values.shape)\n",
    "    print(sensor_data.shape)\n",
    "    print(mask_reshaped.shape)\n",
    "\n",
    "    predicted_values_padded = np.zeros_like(sensor_data)\n",
    "    predicted_values_padded[mask_reshaped == 1] = predicted_values.flatten()\n",
    "    sensor_data[mask_reshaped == 1] = predicted_values_padded[mask_reshaped == 1]\n",
    "    sensor_data = inverse_normalize(sensor_data)\n",
    "\n",
    "    # 先建立 DataFrame，只有 sensor_data（修改後）\n",
    "    final_df = pd.DataFrame(sensor_data)\n",
    "    sensor_columns = [f\"sensor{i+1}\" for i in range(sensor_data.shape[1])]\n",
    "    final_df.columns = sensor_columns\n",
    "    # ── 新增：建立原始感測器數據的 DataFrame ──\n",
    "    ori_sensor_df = pd.DataFrame(sensor_data_ori, columns=[f\"origin_{i+1}\" for i in range(sensor_data_ori.shape[1])])\n",
    "    # ── 新增：計算相對誤差（僅針對 mask 掉的感測器） ──\n",
    "    # 相對誤差 = abs(修改後 - 原始) / abs(原始)\n",
    "    rel_error = np.abs(sensor_data - sensor_data_ori) / np.abs(sensor_data_ori)\n",
    "    # 只保留 mask 區域的誤差，其他設定為 NaN\n",
    "    rel_error[mask_reshaped != 1] = np.nan\n",
    "    # 建立相對誤差的 DataFrame，欄位命名為 mask_1, mask_2, ..., mask_n\n",
    "    rel_error_df = pd.DataFrame(rel_error, columns=[f\"mask_{i+1}\" for i in range(sensor_data.shape[1])])\n",
    "    # ────────────────────────────────────────────────\n",
    "\n",
    "    # ── 新增：計算每個時間步（行）的平均相對誤差（忽略 NaN），新增欄位 \"average\" ──\n",
    "    average_error = rel_error_df.mean(axis=1, skipna=True)\n",
    "    average_error_df = pd.DataFrame(average_error, columns=[\"average\"])\n",
    "    # ────────────────────────────────────────────────\n",
    "\n",
    "    # ── 新增：計算每個時間步（行）中，mask_{編號} 欄位的最大值，新增欄位 \"max\" ──\n",
    "    max_error = rel_error_df.max(axis=1, skipna=True)\n",
    "    max_error_df = pd.DataFrame(max_error, columns=[\"max\"])\n",
    "    # ────────────────────────────────────────────────\n",
    "\n",
    "    # 合併修改後的感測器數據、原始感測器數據、相對誤差、平均相對誤差與最大誤差（橫向合併）\n",
    "    final_df = pd.concat([final_df, ori_sensor_df, rel_error_df, average_error_df, max_error_df], axis=1)\n",
    "    final_df_list.append(final_df)\n",
    "\n",
    "# 合併所有 video 的 DataFrame 成一個 DataFrame，並儲存到同一個 CSV 檔案中\n",
    "all_final_df = pd.concat(final_df_list, axis=0, ignore_index=True)\n",
    "all_final_df.to_csv(f\"{save_path}/final_output.csv\", index=False)\n",
    "\n",
    "print(f\"✅ 所有結果已合併儲存至 {save_path}/final_output.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from timm.models import create_model\n",
    "from utils import NativeScalerWithGradNormCount as NativeScaler\n",
    "import utils\n",
    "from datasets import CSVMAE\n",
    "from einops import rearrange\n",
    "\n",
    "def load_model(model_name, weights_path, device):\n",
    "    print(f\"Loading model: {model_name}\")\n",
    "    model = create_model(\n",
    "        model_name,\n",
    "        pretrained=False,\n",
    "        drop_path_rate=0.0,\n",
    "        drop_block_rate=None,\n",
    "        decoder_depth=4,\n",
    "        use_checkpoint=False\n",
    "    )\n",
    "    checkpoint = torch.load(weights_path, map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['model'], strict=False)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def validate(model, dataloader, device, output_file):\n",
    "    loss_func = torch.nn.MSELoss()\n",
    "    results = []\n",
    "    total_loss = 0.0\n",
    "    num_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for step, (videos, bool_masked_pos) in enumerate(dataloader):\n",
    "\n",
    "            videos = videos.to(device, non_blocking=True)\n",
    "            bool_masked_pos = bool_masked_pos.to(device, non_blocking=True).flatten(1).to(torch.bool)\n",
    "            \n",
    "            videos_patch = rearrange(videos, 'b c (t p0) (h p1) (w p2) -> b (t h w) (p0 p1 p2 c)', p0=2, p1=1, p2=1)\n",
    "            B, _, C = videos_patch.shape\n",
    "            labels = videos_patch[bool_masked_pos].reshape(B, -1, C)\n",
    "            outputs = model(videos, bool_masked_pos)\n",
    "            # **計算 Loss**\n",
    "            loss = loss_func(outputs, labels)\n",
    "            loss_value = loss.item()\n",
    "            total_loss += loss_value\n",
    "            num_samples += 1\n",
    "\n",
    "            print(f\"Step {step + 1}/{len(dataloader)} - Loss: {loss_value:.6f}\")\n",
    "\n",
    "    # 計算平均 Loss\n",
    "    avg_loss = total_loss / num_samples if num_samples > 0 else float('nan')\n",
    "    print(f\"✅ 平均 Loss: {avg_loss:.6f}\")\n",
    "\n",
    "    # **儲存結果**\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write(f\"Average Loss: {avg_loss:.6f}\\n\")\n",
    "        for res in results:\n",
    "            f.write(str(res) + '\\n')\n",
    "\n",
    "    print(f\"Validation results and loss saved to {output_file}\")\n",
    "\n",
    "\n",
    "def run_validation(model_name, weights_path, data_path, batch_size, device, output_file):\n",
    "    if not os.path.exists(data_path):\n",
    "        print(\"Error: Data path does not exist!\")\n",
    "        return\n",
    "    \n",
    "    model = load_model(model_name, weights_path, device)\n",
    "    patch_size = model.encoder.patch_embed.patch_size\n",
    "    window_size = (16 // 2, 4 // patch_size[0], 4 // patch_size[1])\n",
    "    dataset = CSVMAE(root_dir=data_path, num_frames=16, window_size=window_size)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
    "    validate(model, dataloader, device, output_file)\n",
    "\n",
    "model_name = 'pretrain_videomae_base_patch1_4'\n",
    "weights_path = '/mnt/d/haoxiangbiya/VideoMAE/ckpt_output_dir/checkpoint-2499.pth'\n",
    "data_path = '/mnt/d/mae/bigclassroom/foundation_dataset/train'\n",
    "batch_size = 8\n",
    "device = 'cuda'\n",
    "output_file = 'validation_results.txt'\n",
    "\n",
    "run_validation(model_name, weights_path, data_path, batch_size, device, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from masking_generator import TubeMaskingGenerator  # 假設你有這個mask生成器\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "class CustomCSVMAE(Dataset):\n",
    "    def __init__(self, root_dir, num_frames=16, mask_ratio=0.75, patch_size=16, window_size=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.num_frames = num_frames\n",
    "        self.mask_ratio = mask_ratio\n",
    "        self.patch_size = patch_size\n",
    "        self.mask_generator = TubeMaskingGenerator(window_size, mask_ratio=mask_ratio)\n",
    "\n",
    "        # 遞迴地獲取所有 CSV 檔案\n",
    "        self.file_paths = []\n",
    "        for subdir, _, files in os.walk(root_dir):\n",
    "            for file in files:\n",
    "                if file.endswith('.csv'):\n",
    "                    self.file_paths.append(os.path.join(subdir, file))\n",
    "\n",
    "        # 自訂排序函數：按檔案名中的數字時間戳排序\n",
    "        def extract_sort_key(path):\n",
    "            filename = os.path.basename(path)\n",
    "            match = re.match(r\"(.+?)_(\\d+)\\.csv\", filename)  # 擷取類別名稱 & 數字\n",
    "            if match:\n",
    "                category = match.group(1)  # 取得類別名稱 (如 1119-1in3out-mv-mc-mid)\n",
    "                time_value = int(match.group(2))  # 取得數字時間戳\n",
    "                return (category, time_value)\n",
    "            return (filename, 0)  # 若無法匹配則放最後\n",
    "\n",
    "        # 排序後按類別分組\n",
    "        self.file_paths.sort(key=extract_sort_key)\n",
    "        self.groups = defaultdict(list)  # 每個類別對應的 CSV 檔案\n",
    "        for path in self.file_paths:\n",
    "            category = extract_sort_key(path)[0]  # 取得類別名稱\n",
    "            self.groups[category].append(path)\n",
    "\n",
    "        # 按照 num_frames 切割成時間段\n",
    "        self.sequence_groups = []\n",
    "        for category, files in self.groups.items():\n",
    "            if len(files) >= num_frames:\n",
    "                for i in range(len(files) - num_frames + 1):\n",
    "                    self.sequence_groups.append(files[i: i + num_frames])\n",
    "\n",
    "        if not self.sequence_groups:\n",
    "            raise ValueError(f\"CSV 檔案數量不足 {num_frames}，請檢查 `{root_dir}` 資料夾！\")\n",
    "\n",
    "        # 顯示前 5 組數據\n",
    "        print(\"= 加載的 CSV 時間序列組: (顯示前 5 組) =\")\n",
    "        for i, seq in enumerate(self.sequence_groups[:5]):\n",
    "            print(f\"組 {i+1}: {[os.path.basename(f) for f in seq]}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequence_groups)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_list = self.sequence_groups[idx]  # 取得對應的一組 num_frames CSV 檔案\n",
    "        frames = []\n",
    "        bool_masked_pos = []  # 用來儲存每個 frame 的 mask 訊息\n",
    "\n",
    "        # 讀取每個影片的 frames 和對應的 mask\n",
    "        for csv_path in file_list:\n",
    "            data = np.genfromtxt(csv_path, delimiter=',')\n",
    "            frames.append(data)\n",
    "\n",
    "            # 生成 mask，這部分可以使用您先前的 `TubeMaskingGenerator`\n",
    "            mask = np.random.binomial(1, self.mask_ratio, data.shape)  # 隨機生成的 mask\n",
    "            bool_masked_pos.append(mask)\n",
    "\n",
    "        frames = np.stack(frames)  # (T, H, W)\n",
    "        frames = np.expand_dims(frames, axis=0)  # 增加 Channel 維度 (C=1, T, H, W)\n",
    "        frames = torch.tensor(frames, dtype=torch.float32)\n",
    "\n",
    "        bool_masked_pos = np.stack(bool_masked_pos)  # (T, H, W)\n",
    "        bool_masked_pos = torch.tensor(bool_masked_pos, dtype=torch.bool)\n",
    "\n",
    "        return (frames, bool_masked_pos)\n",
    "\n",
    "# 使用示例：\n",
    "csv_folder = \"/path/to/your/csv/folder\"\n",
    "dataset = CustomCSVMAE(root_dir=csv_folder, num_frames=16, mask_ratio=0.75, patch_size=16)\n",
    "\n",
    "# 打印某一組資料，檢查資料是否正確\n",
    "sample_frames, sample_mask = dataset[0]  # 顯示第一組資料\n",
    "print(\"Sample Frames Shape:\", sample_frames.shape)\n",
    "print(\"Sample Mask Shape:\", sample_mask.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "videomae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
