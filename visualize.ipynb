{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from timm.models import create_model\n",
    "import numpy as np\n",
    "# from csvdata import CSVMAE\n",
    "import utils\n",
    "import modeling_pretrain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 參數設定（手動設定，不需要 argparse）\n",
    "csv_folder = \"/mnt/d/mae/bigclassroom/foundation_dataset/456\"   # 輸入 CSV 檔案\n",
    "save_path = \"output_csv\"  # 結果輸出的資料夾\n",
    "model_path = \"ckpt_output_dir/checkpoint-1999.pth\"  # 模型檔案\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # 自動選擇 GPU 或 CPU\n",
    "model_name = \"pretrain_videomae_base_patch1_4\"  # 你的 VideoMAE 模型\n",
    "drop_path = 0.0  # Drop Path Rate   \n",
    "mask_ratio = 0.75  # 設定 Masking 比例 (例如 75%)\n",
    "num_frames = 16\n",
    "decoder_depth = 8\n",
    "patch_size = 1\n",
    "window_size = (num_frames // 2, 4, 4)  # (T, H, W)\n",
    "# 確保輸出資料夾存在\n",
    "Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "csv_files = sorted([f for f in os.listdir(csv_folder) if f.endswith(\".csv\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from masking_generator import TubeMaskingGenerator\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "class CSVMAETEST(Dataset):\n",
    "    def __init__(self, root_dir, num_frames=16, mask_ratio=0.75, window_size=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.num_frames = num_frames\n",
    "        self.window_size = window_size\n",
    "        self.mask_generator = TubeMaskingGenerator(window_size, mask_ratio=mask_ratio)\n",
    "\n",
    "        # 遞迴地獲取所有 CSV 檔案\n",
    "        self.file_paths = []\n",
    "        for subdir, _, files in os.walk(root_dir):\n",
    "            for file in files:\n",
    "                if file.endswith('.csv'):\n",
    "                    self.file_paths.append(os.path.join(subdir, file))\n",
    "\n",
    "        # 自訂排序函數: 先按類別名稱排序，再按數字時間戳排序\n",
    "        def extract_sort_key(path):\n",
    "            filename = os.path.basename(path)\n",
    "            match = re.match(r\"(.+?)_(\\d+)\\.csv\", filename)  # 擷取類別名稱 & 數字\n",
    "            if match:\n",
    "                category = match.group(1)  # 取得類別名稱 (如 1119-1in3out-mv-mc-mid)\n",
    "                time_value = int(match.group(2))  # 取得數字時間戳\n",
    "                return (category, time_value)\n",
    "            return (filename, 0)  # 若無法匹配則放最後\n",
    "\n",
    "        # 排序後按類別分組\n",
    "        self.file_paths.sort(key=extract_sort_key)\n",
    "        self.groups = defaultdict(list)  # 每個類別對應的 CSV 檔案\n",
    "        for path in self.file_paths:\n",
    "            category = extract_sort_key(path)[0]  # 取得類別名稱\n",
    "            self.groups[category].append(path)\n",
    "\n",
    "        # 預先切割成 num_frames 時間段，確保分組不重複\n",
    "        self.sequence_groups = []\n",
    "        for category, files in self.groups.items():\n",
    "            if len(files) >= num_frames:\n",
    "                for i in range(0, len(files) - num_frames + 1, num_frames):  # 修改這裡，使每次分組間隔num_frames\n",
    "                    self.sequence_groups.append(files[i: i + num_frames])\n",
    "\n",
    "        # 檢查是否有可用數據\n",
    "        if not self.sequence_groups:\n",
    "            raise ValueError(f\"CSV 檔案數量不足 {num_frames}，請檢查 `{root_dir}` 資料夾！\")\n",
    "\n",
    "        # 顯示前 5 組數據確認順序\n",
    "        print(\"= 加載的 CSV 時間序列組: (顯示前 5 組) =\")\n",
    "        for i, seq in enumerate(self.sequence_groups[:5]):\n",
    "            print(f\"組 {i+1}: {[os.path.basename(f) for f in seq]}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequence_groups)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_list = self.sequence_groups[idx]  # 取得對應的一組 num_frames CSV 檔案\n",
    "        frames = []\n",
    "        for csv_path in file_list:\n",
    "            data = np.genfromtxt(csv_path, delimiter=',')\n",
    "            frames.append(data)\n",
    "\n",
    "        frames = np.stack(frames)  # (T, H, W)\n",
    "\n",
    "        # 增加 Channel 維度 -> (C=1, T, H, W)\n",
    "        frames = np.expand_dims(frames, axis=0)\n",
    "        frames = torch.tensor(frames, dtype=torch.float32)\n",
    "\n",
    "        # 生成 mask\n",
    "        mask = self.mask_generator()\n",
    "\n",
    "        return (frames, mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= 加載的 CSV 時間序列組: (顯示前 5 組) =\n",
      "組 1: ['1119-1in3out-mv-mc-mid_5.csv', '1119-1in3out-mv-mc-mid_10.csv', '1119-1in3out-mv-mc-mid_15.csv', '1119-1in3out-mv-mc-mid_20.csv', '1119-1in3out-mv-mc-mid_25.csv', '1119-1in3out-mv-mc-mid_30.csv', '1119-1in3out-mv-mc-mid_35.csv', '1119-1in3out-mv-mc-mid_40.csv', '1119-1in3out-mv-mc-mid_45.csv', '1119-1in3out-mv-mc-mid_50.csv', '1119-1in3out-mv-mc-mid_55.csv', '1119-1in3out-mv-mc-mid_60.csv', '1119-1in3out-mv-mc-mid_65.csv', '1119-1in3out-mv-mc-mid_70.csv', '1119-1in3out-mv-mc-mid_75.csv', '1119-1in3out-mv-mc-mid_80.csv']\n",
      "組 2: ['1119-1in3out-mv-mc-mid_85.csv', '1119-1in3out-mv-mc-mid_90.csv', '1119-1in3out-mv-mc-mid_95.csv', '1119-1in3out-mv-mc-mid_100.csv', '1119-1in3out-mv-mc-mid_105.csv', '1119-1in3out-mv-mc-mid_110.csv', '1119-1in3out-mv-mc-mid_115.csv', '1119-1in3out-mv-mc-mid_120.csv', '1119-1in3out-mv-mc-mid_125.csv', '1119-1in3out-mv-mc-mid_130.csv', '1119-1in3out-mv-mc-mid_135.csv', '1119-1in3out-mv-mc-mid_140.csv', '1119-1in3out-mv-mc-mid_145.csv', '1119-1in3out-mv-mc-mid_150.csv', '1119-1in3out-mv-mc-mid_155.csv', '1119-1in3out-mv-mc-mid_160.csv']\n",
      "組 3: ['1119-1in3out-mv-mc-mid_165.csv', '1119-1in3out-mv-mc-mid_170.csv', '1119-1in3out-mv-mc-mid_175.csv', '1119-1in3out-mv-mc-mid_180.csv', '1119-1in3out-mv-mc-mid_185.csv', '1119-1in3out-mv-mc-mid_190.csv', '1119-1in3out-mv-mc-mid_195.csv', '1119-1in3out-mv-mc-mid_200.csv', '1119-1in3out-mv-mc-mid_205.csv', '1119-1in3out-mv-mc-mid_210.csv', '1119-1in3out-mv-mc-mid_215.csv', '1119-1in3out-mv-mc-mid_220.csv', '1119-1in3out-mv-mc-mid_225.csv', '1119-1in3out-mv-mc-mid_230.csv', '1119-1in3out-mv-mc-mid_235.csv', '1119-1in3out-mv-mc-mid_240.csv']\n",
      "組 4: ['1119-1in3out-mv-mc-mid_245.csv', '1119-1in3out-mv-mc-mid_250.csv', '1119-1in3out-mv-mc-mid_255.csv', '1119-1in3out-mv-mc-mid_260.csv', '1119-1in3out-mv-mc-mid_265.csv', '1119-1in3out-mv-mc-mid_270.csv', '1119-1in3out-mv-mc-mid_275.csv', '1119-1in3out-mv-mc-mid_280.csv', '1119-1in3out-mv-mc-mid_285.csv', '1119-1in3out-mv-mc-mid_290.csv', '1119-1in3out-mv-mc-mid_295.csv', '1119-1in3out-mv-mc-mid_300.csv', '1119-1in3out-mv-mc-mid_305.csv', '1119-1in3out-mv-mc-mid_310.csv', '1119-1in3out-mv-mc-mid_315.csv', '1119-1in3out-mv-mc-mid_320.csv']\n",
      "組 5: ['1119-1in3out-mv-mc-mid_325.csv', '1119-1in3out-mv-mc-mid_330.csv', '1119-1in3out-mv-mc-mid_335.csv', '1119-1in3out-mv-mc-mid_340.csv', '1119-1in3out-mv-mc-mid_345.csv', '1119-1in3out-mv-mc-mid_350.csv', '1119-1in3out-mv-mc-mid_355.csv', '1119-1in3out-mv-mc-mid_360.csv', '1119-1in3out-mv-mc-mid_365.csv', '1119-1in3out-mv-mc-mid_370.csv', '1119-1in3out-mv-mc-mid_375.csv', '1119-1in3out-mv-mc-mid_380.csv', '1119-1in3out-mv-mc-mid_385.csv', '1119-1in3out-mv-mc-mid_390.csv', '1119-1in3out-mv-mc-mid_395.csv', '1119-1in3out-mv-mc-mid_400.csv']\n",
      "Loading model: pretrain_videomae_base_patch1_4\n",
      "pretrain_videomae_base_patch1_4 is being executed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2319742/4187398625.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=\"cpu\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PretrainVisionTransformer(\n",
       "  (encoder): PretrainVisionTransformerEncoder(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv3d(1, 768, kernel_size=(2, 1, 1), stride=(2, 1, 1))\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0-11): 12 x Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (head): Identity()\n",
       "  )\n",
       "  (decoder): PretrainVisionTransformerDecoder(\n",
       "    (blocks): ModuleList(\n",
       "      (0-7): 8 x Block(\n",
       "        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "    (head): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       "  (encoder_to_decoder): Linear(in_features=768, out_features=512, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = CSVMAETEST(root_dir=csv_folder, num_frames=num_frames, mask_ratio=mask_ratio, window_size=window_size)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "print(f\"Loading model: {model_name}\")\n",
    "\n",
    "model = create_model(\n",
    "        model_name,\n",
    "        pretrained=False,\n",
    "        drop_path_rate=0,\n",
    "        drop_block_rate=None,\n",
    "        decoder_depth=decoder_depth,\n",
    "        use_checkpoint=model_path\n",
    "    )\n",
    "checkpoint = torch.load(model_path, map_location=\"cpu\")\n",
    "model.load_state_dict(checkpoint[\"model\"])\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_normalize(log_normalized_values):\n",
    "    # 將 0~1 的正規化數據反轉回 log 範圍，然後再轉回線性空間的原始範圍\n",
    "    original_min = 300\n",
    "    original_max = 1600\n",
    "    log_values = log_normalized_values * (np.log(original_max) - np.log(original_min)) + np.log(original_min)\n",
    "    original_values = np.exp(log_values)\n",
    "    return original_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for video 0: 0.011690905317664146\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (96, 2)\n",
      "(16, 12)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "✅ Video 0 結果已儲存至 output_csv/final_output_0.csv\n",
      "Loss for video 1: 0.008535642176866531\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (96, 2)\n",
      "(16, 12)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "✅ Video 1 結果已儲存至 output_csv/final_output_1.csv\n",
      "Loss for video 2: 0.004539229907095432\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (96, 2)\n",
      "(16, 12)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "✅ Video 2 結果已儲存至 output_csv/final_output_2.csv\n",
      "Loss for video 3: 0.003322185017168522\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (96, 2)\n",
      "(16, 12)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "✅ Video 3 結果已儲存至 output_csv/final_output_3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for video 4: 0.003004766535013914\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (96, 2)\n",
      "(16, 12)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "✅ Video 4 結果已儲存至 output_csv/final_output_4.csv\n",
      "Loss for video 5: 0.0028815343976020813\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (96, 2)\n",
      "(16, 12)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "✅ Video 5 結果已儲存至 output_csv/final_output_5.csv\n",
      "Loss for video 6: 0.0030954480171203613\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (96, 2)\n",
      "(16, 12)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "✅ Video 6 結果已儲存至 output_csv/final_output_6.csv\n",
      "Loss for video 7: 0.0028788677882403135\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (96, 2)\n",
      "(16, 12)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "✅ Video 7 結果已儲存至 output_csv/final_output_7.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for video 8: 0.0035263828467577696\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (96, 2)\n",
      "(16, 12)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "✅ Video 8 結果已儲存至 output_csv/final_output_8.csv\n",
      "Loss for video 9: 0.001438829000107944\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (96, 2)\n",
      "(16, 12)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "✅ Video 9 結果已儲存至 output_csv/final_output_9.csv\n",
      "Loss for video 10: 0.007211784832179546\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (96, 2)\n",
      "(16, 12)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "✅ Video 10 結果已儲存至 output_csv/final_output_10.csv\n",
      "Loss for video 11: 0.0030758732464164495\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (96, 2)\n",
      "(16, 12)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "✅ Video 11 結果已儲存至 output_csv/final_output_11.csv\n",
      "Loss for video 12: 0.003920829854905605\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (96, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 12)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "✅ Video 12 結果已儲存至 output_csv/final_output_12.csv\n",
      "Loss for video 13: 0.004776531830430031\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (96, 2)\n",
      "(16, 12)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "✅ Video 13 結果已儲存至 output_csv/final_output_13.csv\n",
      "Loss for video 14: 0.0020118195097893476\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (96, 2)\n",
      "(16, 12)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "✅ Video 14 結果已儲存至 output_csv/final_output_14.csv\n",
      "Loss for video 15: 0.008160900324583054\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (96, 2)\n",
      "(16, 12)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "✅ Video 15 結果已儲存至 output_csv/final_output_15.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for video 16: 0.0026139100082218647\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (96, 2)\n",
      "(16, 12)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "✅ Video 16 結果已儲存至 output_csv/final_output_16.csv\n",
      "Loss for video 17: 0.004893605597317219\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (96, 2)\n",
      "(16, 12)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "✅ Video 17 結果已儲存至 output_csv/final_output_17.csv\n",
      "Loss for video 18: 0.006873867940157652\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (96, 2)\n",
      "(16, 12)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "✅ Video 18 結果已儲存至 output_csv/final_output_18.csv\n",
      "Loss for video 19: 0.00727284699678421\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (96, 2)\n",
      "(16, 12)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "✅ Video 19 結果已儲存至 output_csv/final_output_19.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for video 20: 0.0036284083034843206\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (96, 2)\n",
      "(16, 12)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "✅ Video 20 結果已儲存至 output_csv/final_output_20.csv\n",
      "Loss for video 21: 0.005734368227422237\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (96, 2)\n",
      "(16, 12)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "✅ Video 21 結果已儲存至 output_csv/final_output_21.csv\n",
      "Loss for video 22: 0.004891693592071533\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (96, 2)\n",
      "(16, 12)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "✅ Video 22 結果已儲存至 output_csv/final_output_22.csv\n",
      "Loss for video 23: 0.003918604925274849\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (96, 2)\n",
      "(16, 12)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "✅ Video 23 結果已儲存至 output_csv/final_output_23.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for video 24: 0.008214897476136684\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (96, 2)\n",
      "(16, 12)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "✅ Video 24 結果已儲存至 output_csv/final_output_24.csv\n",
      "Loss for video 25: 0.004668105393648148\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (96, 2)\n",
      "(16, 12)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "✅ Video 25 結果已儲存至 output_csv/final_output_25.csv\n",
      "Loss for video 26: 0.006916258484125137\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (96, 2)\n",
      "(16, 12)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "✅ Video 26 結果已儲存至 output_csv/final_output_26.csv\n",
      "Loss for video 27: 0.003576758084818721\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (96, 2)\n",
      "(16, 12)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "✅ Video 27 結果已儲存至 output_csv/final_output_27.csv\n",
      "Loss for video 28: 0.006916931830346584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (96, 2)\n",
      "(16, 12)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "✅ Video 28 結果已儲存至 output_csv/final_output_28.csv\n",
      "Loss for video 29: 0.008237301371991634\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (96, 2)\n",
      "(16, 12)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "✅ Video 29 結果已儲存至 output_csv/final_output_29.csv\n",
      "Loss for video 30: 0.009567607194185257\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (96, 2)\n",
      "(16, 12)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "✅ Video 30 結果已儲存至 output_csv/final_output_30.csv\n",
      "Loss for video 31: 0.0034799929708242416\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (96, 2)\n",
      "(16, 12)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "✅ Video 31 結果已儲存至 output_csv/final_output_31.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for video 32: 0.009279794991016388\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (96, 2)\n",
      "(16, 12)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "✅ Video 32 結果已儲存至 output_csv/final_output_32.csv\n",
      "Loss for video 33: 0.007987565360963345\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (96, 2)\n",
      "(16, 12)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "✅ Video 33 結果已儲存至 output_csv/final_output_33.csv\n",
      "Loss for video 34: 0.007460962515324354\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (96, 2)\n",
      "(16, 12)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "✅ Video 34 結果已儲存至 output_csv/final_output_34.csv\n",
      "Loss for video 35: 0.004833603743463755\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (96, 2)\n",
      "(16, 12)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "✅ Video 35 結果已儲存至 output_csv/final_output_35.csv\n",
      "Loss for video 36: 0.007086483296006918\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (96, 2)\n",
      "(16, 12)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "✅ Video 36 結果已儲存至 output_csv/final_output_36.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for video 37: 0.0024790153838694096\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (96, 2)\n",
      "(16, 12)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "✅ Video 37 結果已儲存至 output_csv/final_output_37.csv\n",
      "Loss for video 38: 0.008927753195166588\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (96, 2)\n",
      "(16, 12)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "✅ Video 38 結果已儲存至 output_csv/final_output_38.csv\n",
      "Loss for video 39: 0.004233098588883877\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (96, 2)\n",
      "(16, 12)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "✅ Video 39 結果已儲存至 output_csv/final_output_39.csv\n",
      "Loss for video 40: 0.002145943697541952\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (96, 2)\n",
      "(16, 12)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "✅ Video 40 結果已儲存至 output_csv/final_output_40.csv\n",
      "Loss for video 41: 0.0071341292932629585\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (96, 2)\n",
      "(16, 12)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "✅ Video 41 結果已儲存至 output_csv/final_output_41.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for video 42: 0.008114620111882687\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (96, 2)\n",
      "(16, 12)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "✅ Video 42 結果已儲存至 output_csv/final_output_42.csv\n",
      "Loss for video 43: 0.007708774879574776\n",
      "🔍 原始 mask 形狀: (128, 1)\n",
      "🔍 原始 output 形狀: (96, 2)\n",
      "(16, 12)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "✅ Video 43 結果已儲存至 output_csv/final_output_43.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from einops import rearrange\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "# 逐個 video 處理並儲存\n",
    "for idx, (videos, bool_masked_pos) in enumerate(dataloader):\n",
    "    videos = videos.to(device, non_blocking=True)\n",
    "    bool_masked_pos = bool_masked_pos.to(device, non_blocking=True).flatten(1).to(torch.bool)\n",
    "\n",
    "    # 進行推理\n",
    "    with torch.no_grad():\n",
    "        # Rearrange and process the frames\n",
    "        videos_patch = rearrange(videos, 'b c (t p0) (h p1) (w p2) -> b (t h w) (p0 p1 p2 c)', p0=2, p1=patch_size, p2=patch_size)\n",
    "        B, _, C = videos_patch.shape\n",
    "\n",
    "        labels = videos_patch[bool_masked_pos].reshape(B, -1, C)\n",
    "        outputs = model(videos, bool_masked_pos)\n",
    "        loss = loss_func(input=outputs, target=labels)\n",
    "        print(f\"Loss for video {idx}: {loss.item()}\")\n",
    "\n",
    "    # 轉換為 NumPy 格式\n",
    "    outputs_np = outputs.cpu().detach().numpy().reshape(-1, 2)  # (N_mask, C)\n",
    "    mask_np = bool_masked_pos.cpu().detach().numpy().reshape(-1).astype(int)  # (N,)\n",
    "\n",
    "    # ✅ **即時儲存結果**\n",
    "    output_list = [outputs_np]\n",
    "    mask_list = [mask_np]\n",
    "\n",
    "    # 儲存為 CSV (攤平成一維)\n",
    "    df_outputs = pd.DataFrame(np.concatenate(output_list, axis=0))  # (N, C)\n",
    "    df_masks = pd.DataFrame(np.concatenate(mask_list, axis=0))  # (N,)\n",
    "\n",
    "    print(\"🔍 原始 mask 形狀:\", df_masks.shape)\n",
    "    print(\"🔍 原始 output 形狀:\", df_outputs.shape)\n",
    "\n",
    "    # **還原完整的感測器數據**\n",
    "    sensor_data = videos.cpu().detach().numpy().squeeze(0)  # (C=1, T, H, W) → (T, H, W)\n",
    "    sensor_data = sensor_data.reshape(num_frames, -1)  # 轉換為 (T, sensors)\n",
    "\n",
    "    # **mask=1 的地方用 `df_outputs` 預測值替換**\n",
    "    predicted_values = df_outputs.to_numpy().reshape(num_frames, -1)  # (T, 預測的 sensor 值)\n",
    "    mask_reshaped = df_masks.to_numpy().reshape(-1, num_frames)  # (H × W, T) → (T, H × W)\n",
    "    mask_reshaped = np.tile(mask_reshaped, (2, 1))\n",
    "\n",
    "    print(predicted_values.shape)\n",
    "    print(sensor_data.shape)\n",
    "    print(mask_reshaped.shape)\n",
    "\n",
    "    # 創建與 sensor_data 相同形狀的空矩陣 (16, 16)\n",
    "    predicted_values_padded = np.zeros_like(sensor_data)\n",
    "\n",
    "    # 只填充 mask=1 的部分\n",
    "    predicted_values_padded[mask_reshaped == 1] = predicted_values.flatten()\n",
    "\n",
    "    sensor_data[mask_reshaped == 1] = predicted_values_padded[mask_reshaped == 1]  # 只替換 mask=1 的值\n",
    "    sensor_data = inverse_normalize(sensor_data)\n",
    "\n",
    "    # 先建立 DataFrame，只有 sensor_data\n",
    "    final_df = pd.DataFrame(sensor_data)  # 先只加入 sensor_data\n",
    "\n",
    "    # **命名欄位**\n",
    "    sensor_columns = [f\"sensor{i+1}\" for i in range(sensor_data.shape[1])]\n",
    "\n",
    "    final_df.columns = sensor_columns  # 先設定 sensor 欄位名稱\n",
    "\n",
    "    mask_reshaped = mask_reshaped.reshape(sensor_data.shape)  # (T, H×W)\n",
    "\n",
    "    final_df[\"mask\"] = mask_reshaped[0].flatten()  # 直接在 DataFrame 內加入 mask\n",
    "\n",
    "    # **即時儲存最終結果**\n",
    "    final_df.to_csv(f\"{save_path}/final_output_{idx}.csv\", index=False)\n",
    "\n",
    "    print(f\"✅ Video {idx} 結果已儲存至 {save_path}/final_output_{idx}.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from timm.models import create_model\n",
    "from utils import NativeScalerWithGradNormCount as NativeScaler\n",
    "import utils\n",
    "from datasets import CSVMAE\n",
    "from einops import rearrange\n",
    "\n",
    "def load_model(model_name, weights_path, device):\n",
    "    print(f\"Loading model: {model_name}\")\n",
    "    model = create_model(\n",
    "        model_name,\n",
    "        pretrained=False,\n",
    "        drop_path_rate=0.0,\n",
    "        drop_block_rate=None,\n",
    "        decoder_depth=4,\n",
    "        use_checkpoint=False\n",
    "    )\n",
    "    checkpoint = torch.load(weights_path, map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['model'], strict=False)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def validate(model, dataloader, device, output_file):\n",
    "    loss_func = torch.nn.MSELoss()\n",
    "    results = []\n",
    "    total_loss = 0.0\n",
    "    num_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for step, (videos, bool_masked_pos) in enumerate(dataloader):\n",
    "\n",
    "            videos = videos.to(device, non_blocking=True)\n",
    "            bool_masked_pos = bool_masked_pos.to(device, non_blocking=True).flatten(1).to(torch.bool)\n",
    "            \n",
    "            videos_patch = rearrange(videos, 'b c (t p0) (h p1) (w p2) -> b (t h w) (p0 p1 p2 c)', p0=2, p1=1, p2=1)\n",
    "            B, _, C = videos_patch.shape\n",
    "            labels = videos_patch[bool_masked_pos].reshape(B, -1, C)\n",
    "            outputs = model(videos, bool_masked_pos)\n",
    "            # **計算 Loss**\n",
    "            loss = loss_func(outputs, labels)\n",
    "            loss_value = loss.item()\n",
    "            total_loss += loss_value\n",
    "            num_samples += 1\n",
    "\n",
    "            print(f\"Step {step + 1}/{len(dataloader)} - Loss: {loss_value:.6f}\")\n",
    "\n",
    "    # 計算平均 Loss\n",
    "    avg_loss = total_loss / num_samples if num_samples > 0 else float('nan')\n",
    "    print(f\"✅ 平均 Loss: {avg_loss:.6f}\")\n",
    "\n",
    "    # **儲存結果**\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write(f\"Average Loss: {avg_loss:.6f}\\n\")\n",
    "        for res in results:\n",
    "            f.write(str(res) + '\\n')\n",
    "\n",
    "    print(f\"Validation results and loss saved to {output_file}\")\n",
    "\n",
    "\n",
    "def run_validation(model_name, weights_path, data_path, batch_size, device, output_file):\n",
    "    if not os.path.exists(data_path):\n",
    "        print(\"Error: Data path does not exist!\")\n",
    "        return\n",
    "    \n",
    "    model = load_model(model_name, weights_path, device)\n",
    "    patch_size = model.encoder.patch_embed.patch_size\n",
    "    window_size = (16 // 2, 4 // patch_size[0], 4 // patch_size[1])\n",
    "    dataset = CSVMAE(root_dir=data_path, num_frames=16, window_size=window_size)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
    "    validate(model, dataloader, device, output_file)\n",
    "\n",
    "model_name = 'pretrain_videomae_base_patch1_4'\n",
    "weights_path = '/mnt/d/haoxiangbiya/VideoMAE/ckpt_output_dir/checkpoint-2499.pth'\n",
    "data_path = '/mnt/d/mae/bigclassroom/foundation_dataset/train'\n",
    "batch_size = 8\n",
    "device = 'cuda'\n",
    "output_file = 'validation_results.txt'\n",
    "\n",
    "run_validation(model_name, weights_path, data_path, batch_size, device, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from masking_generator import TubeMaskingGenerator  # 假設你有這個mask生成器\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "class CustomCSVMAE(Dataset):\n",
    "    def __init__(self, root_dir, num_frames=16, mask_ratio=0.75, patch_size=16, window_size=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.num_frames = num_frames\n",
    "        self.mask_ratio = mask_ratio\n",
    "        self.patch_size = patch_size\n",
    "        self.mask_generator = TubeMaskingGenerator(window_size, mask_ratio=mask_ratio)\n",
    "\n",
    "        # 遞迴地獲取所有 CSV 檔案\n",
    "        self.file_paths = []\n",
    "        for subdir, _, files in os.walk(root_dir):\n",
    "            for file in files:\n",
    "                if file.endswith('.csv'):\n",
    "                    self.file_paths.append(os.path.join(subdir, file))\n",
    "\n",
    "        # 自訂排序函數：按檔案名中的數字時間戳排序\n",
    "        def extract_sort_key(path):\n",
    "            filename = os.path.basename(path)\n",
    "            match = re.match(r\"(.+?)_(\\d+)\\.csv\", filename)  # 擷取類別名稱 & 數字\n",
    "            if match:\n",
    "                category = match.group(1)  # 取得類別名稱 (如 1119-1in3out-mv-mc-mid)\n",
    "                time_value = int(match.group(2))  # 取得數字時間戳\n",
    "                return (category, time_value)\n",
    "            return (filename, 0)  # 若無法匹配則放最後\n",
    "\n",
    "        # 排序後按類別分組\n",
    "        self.file_paths.sort(key=extract_sort_key)\n",
    "        self.groups = defaultdict(list)  # 每個類別對應的 CSV 檔案\n",
    "        for path in self.file_paths:\n",
    "            category = extract_sort_key(path)[0]  # 取得類別名稱\n",
    "            self.groups[category].append(path)\n",
    "\n",
    "        # 按照 num_frames 切割成時間段\n",
    "        self.sequence_groups = []\n",
    "        for category, files in self.groups.items():\n",
    "            if len(files) >= num_frames:\n",
    "                for i in range(len(files) - num_frames + 1):\n",
    "                    self.sequence_groups.append(files[i: i + num_frames])\n",
    "\n",
    "        if not self.sequence_groups:\n",
    "            raise ValueError(f\"CSV 檔案數量不足 {num_frames}，請檢查 `{root_dir}` 資料夾！\")\n",
    "\n",
    "        # 顯示前 5 組數據\n",
    "        print(\"= 加載的 CSV 時間序列組: (顯示前 5 組) =\")\n",
    "        for i, seq in enumerate(self.sequence_groups[:5]):\n",
    "            print(f\"組 {i+1}: {[os.path.basename(f) for f in seq]}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequence_groups)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_list = self.sequence_groups[idx]  # 取得對應的一組 num_frames CSV 檔案\n",
    "        frames = []\n",
    "        bool_masked_pos = []  # 用來儲存每個 frame 的 mask 訊息\n",
    "\n",
    "        # 讀取每個影片的 frames 和對應的 mask\n",
    "        for csv_path in file_list:\n",
    "            data = np.genfromtxt(csv_path, delimiter=',')\n",
    "            frames.append(data)\n",
    "\n",
    "            # 生成 mask，這部分可以使用您先前的 `TubeMaskingGenerator`\n",
    "            mask = np.random.binomial(1, self.mask_ratio, data.shape)  # 隨機生成的 mask\n",
    "            bool_masked_pos.append(mask)\n",
    "\n",
    "        frames = np.stack(frames)  # (T, H, W)\n",
    "        frames = np.expand_dims(frames, axis=0)  # 增加 Channel 維度 (C=1, T, H, W)\n",
    "        frames = torch.tensor(frames, dtype=torch.float32)\n",
    "\n",
    "        bool_masked_pos = np.stack(bool_masked_pos)  # (T, H, W)\n",
    "        bool_masked_pos = torch.tensor(bool_masked_pos, dtype=torch.bool)\n",
    "\n",
    "        return (frames, bool_masked_pos)\n",
    "\n",
    "# 使用示例：\n",
    "csv_folder = \"/path/to/your/csv/folder\"\n",
    "dataset = CustomCSVMAE(root_dir=csv_folder, num_frames=16, mask_ratio=0.75, patch_size=16)\n",
    "\n",
    "# 打印某一組資料，檢查資料是否正確\n",
    "sample_frames, sample_mask = dataset[0]  # 顯示第一組資料\n",
    "print(\"Sample Frames Shape:\", sample_frames.shape)\n",
    "print(\"Sample Mask Shape:\", sample_mask.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "videomae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
