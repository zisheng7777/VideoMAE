{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from timm.models import create_model\n",
    "import numpy as np\n",
    "# from csvdata import CSVMAE\n",
    "import utils\n",
    "import modeling_pretrain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åƒæ•¸è¨­å®šï¼ˆæ‰‹å‹•è¨­å®šï¼Œä¸éœ€è¦ argparseï¼‰\n",
    "csv_folder = \"/mnt/d/mae/bigclassroom/foundation_dataset/456\"   # è¼¸å…¥ CSV æª”æ¡ˆ\n",
    "save_path = \"output_csv\"  # çµæœè¼¸å‡ºçš„è³‡æ–™å¤¾\n",
    "model_path = \"ckpt_output_dir/checkpoint-1999.pth\"  # æ¨¡å‹æª”æ¡ˆ\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # è‡ªå‹•é¸æ“‡ GPU æˆ– CPU\n",
    "model_name = \"pretrain_videomae_base_patch1_4\"  # ä½ çš„ VideoMAE æ¨¡å‹\n",
    "drop_path = 0.0  # Drop Path Rate   \n",
    "mask_ratio = 0.75  # è¨­å®š Masking æ¯”ä¾‹ (ä¾‹å¦‚ 75%)\n",
    "num_frames = 16\n",
    "decoder_depth = 8\n",
    "patch_size = 1\n",
    "window_size = (num_frames // 2, 4, 4)  # (T, H, W)\n",
    "# ç¢ºä¿è¼¸å‡ºè³‡æ–™å¤¾å­˜åœ¨\n",
    "Path(save_path).mkdir(parents=True, exist_ok=True)\n",
    "csv_files = sorted([f for f in os.listdir(csv_folder) if f.endswith(\".csv\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_mask = [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from masking_generator import TubeMaskingGenerator\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "class CSVMAETEST(Dataset):\n",
    "    def __init__(self, root_dir, num_frames=16, mask_ratio=0.75, window_size=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.num_frames = num_frames\n",
    "        self.window_size = window_size\n",
    "        self.mask_generator = TubeMaskingGenerator(window_size, mask_ratio=mask_ratio, custom_mask=custom_mask)\n",
    "\n",
    "        # éè¿´åœ°ç²å–æ‰€æœ‰ CSV æª”æ¡ˆ\n",
    "        self.file_paths = []\n",
    "        for subdir, _, files in os.walk(root_dir):\n",
    "            for file in files:\n",
    "                if file.endswith('.csv'):\n",
    "                    self.file_paths.append(os.path.join(subdir, file))\n",
    "\n",
    "        # è‡ªè¨‚æ’åºå‡½æ•¸: å…ˆæŒ‰é¡åˆ¥åç¨±æ’åºï¼Œå†æŒ‰æ•¸å­—æ™‚é–“æˆ³æ’åº\n",
    "        def extract_sort_key(path):\n",
    "            filename = os.path.basename(path)\n",
    "            match = re.match(r\"(.+?)_(\\d+)\\.csv\", filename)  # æ“·å–é¡åˆ¥åç¨± & æ•¸å­—\n",
    "            if match:\n",
    "                category = match.group(1)  # å–å¾—é¡åˆ¥åç¨± (å¦‚ 1119-1in3out-mv-mc-mid)\n",
    "                time_value = int(match.group(2))  # å–å¾—æ•¸å­—æ™‚é–“æˆ³\n",
    "                return (category, time_value)\n",
    "            return (filename, 0)  # è‹¥ç„¡æ³•åŒ¹é…å‰‡æ”¾æœ€å¾Œ\n",
    "\n",
    "        # æ’åºå¾ŒæŒ‰é¡åˆ¥åˆ†çµ„\n",
    "        self.file_paths.sort(key=extract_sort_key)\n",
    "        self.groups = defaultdict(list)  # æ¯å€‹é¡åˆ¥å°æ‡‰çš„ CSV æª”æ¡ˆ\n",
    "        for path in self.file_paths:\n",
    "            category = extract_sort_key(path)[0]  # å–å¾—é¡åˆ¥åç¨±\n",
    "            self.groups[category].append(path)\n",
    "\n",
    "        # é å…ˆåˆ‡å‰²æˆ num_frames æ™‚é–“æ®µï¼Œç¢ºä¿åˆ†çµ„ä¸é‡è¤‡\n",
    "        self.sequence_groups = []\n",
    "        for category, files in self.groups.items():\n",
    "            if len(files) >= num_frames:\n",
    "                for i in range(0, len(files) - num_frames + 1, num_frames):  # ä¿®æ”¹é€™è£¡ï¼Œä½¿æ¯æ¬¡åˆ†çµ„é–“éš”num_frames\n",
    "                    self.sequence_groups.append(files[i: i + num_frames])\n",
    "\n",
    "        # æª¢æŸ¥æ˜¯å¦æœ‰å¯ç”¨æ•¸æ“š\n",
    "        if not self.sequence_groups:\n",
    "            raise ValueError(f\"CSV æª”æ¡ˆæ•¸é‡ä¸è¶³ {num_frames}ï¼Œè«‹æª¢æŸ¥ `{root_dir}` è³‡æ–™å¤¾ï¼\")\n",
    "\n",
    "        # é¡¯ç¤ºå‰ 5 çµ„æ•¸æ“šç¢ºèªé †åº\n",
    "        print(\"= åŠ è¼‰çš„ CSV æ™‚é–“åºåˆ—çµ„: (é¡¯ç¤ºå‰ 5 çµ„) =\")\n",
    "        for i, seq in enumerate(self.sequence_groups[:5]):\n",
    "            print(f\"çµ„ {i+1}: {[os.path.basename(f) for f in seq]}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequence_groups)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_list = self.sequence_groups[idx]  # å–å¾—å°æ‡‰çš„ä¸€çµ„ num_frames CSV æª”æ¡ˆ\n",
    "        frames = []\n",
    "        for csv_path in file_list:\n",
    "            data = np.genfromtxt(csv_path, delimiter=',')\n",
    "            frames.append(data)\n",
    "\n",
    "        frames = np.stack(frames)  # (T, H, W)\n",
    "\n",
    "        # å¢åŠ  Channel ç¶­åº¦ -> (C=1, T, H, W)\n",
    "        frames = np.expand_dims(frames, axis=0)\n",
    "        frames = torch.tensor(frames, dtype=torch.float32)\n",
    "\n",
    "        # ç”Ÿæˆ mask\n",
    "        mask = self.mask_generator()\n",
    "\n",
    "        return (frames, mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "= åŠ è¼‰çš„ CSV æ™‚é–“åºåˆ—çµ„: (é¡¯ç¤ºå‰ 5 çµ„) =\n",
      "çµ„ 1: ['1119-1in3out-mv-mc-mid_5.csv', '1119-1in3out-mv-mc-mid_10.csv', '1119-1in3out-mv-mc-mid_15.csv', '1119-1in3out-mv-mc-mid_20.csv', '1119-1in3out-mv-mc-mid_25.csv', '1119-1in3out-mv-mc-mid_30.csv', '1119-1in3out-mv-mc-mid_35.csv', '1119-1in3out-mv-mc-mid_40.csv', '1119-1in3out-mv-mc-mid_45.csv', '1119-1in3out-mv-mc-mid_50.csv', '1119-1in3out-mv-mc-mid_55.csv', '1119-1in3out-mv-mc-mid_60.csv', '1119-1in3out-mv-mc-mid_65.csv', '1119-1in3out-mv-mc-mid_70.csv', '1119-1in3out-mv-mc-mid_75.csv', '1119-1in3out-mv-mc-mid_80.csv']\n",
      "çµ„ 2: ['1119-1in3out-mv-mc-mid_85.csv', '1119-1in3out-mv-mc-mid_90.csv', '1119-1in3out-mv-mc-mid_95.csv', '1119-1in3out-mv-mc-mid_100.csv', '1119-1in3out-mv-mc-mid_105.csv', '1119-1in3out-mv-mc-mid_110.csv', '1119-1in3out-mv-mc-mid_115.csv', '1119-1in3out-mv-mc-mid_120.csv', '1119-1in3out-mv-mc-mid_125.csv', '1119-1in3out-mv-mc-mid_130.csv', '1119-1in3out-mv-mc-mid_135.csv', '1119-1in3out-mv-mc-mid_140.csv', '1119-1in3out-mv-mc-mid_145.csv', '1119-1in3out-mv-mc-mid_150.csv', '1119-1in3out-mv-mc-mid_155.csv', '1119-1in3out-mv-mc-mid_160.csv']\n",
      "çµ„ 3: ['1119-1in3out-mv-mc-mid_165.csv', '1119-1in3out-mv-mc-mid_170.csv', '1119-1in3out-mv-mc-mid_175.csv', '1119-1in3out-mv-mc-mid_180.csv', '1119-1in3out-mv-mc-mid_185.csv', '1119-1in3out-mv-mc-mid_190.csv', '1119-1in3out-mv-mc-mid_195.csv', '1119-1in3out-mv-mc-mid_200.csv', '1119-1in3out-mv-mc-mid_205.csv', '1119-1in3out-mv-mc-mid_210.csv', '1119-1in3out-mv-mc-mid_215.csv', '1119-1in3out-mv-mc-mid_220.csv', '1119-1in3out-mv-mc-mid_225.csv', '1119-1in3out-mv-mc-mid_230.csv', '1119-1in3out-mv-mc-mid_235.csv', '1119-1in3out-mv-mc-mid_240.csv']\n",
      "çµ„ 4: ['1119-1in3out-mv-mc-mid_245.csv', '1119-1in3out-mv-mc-mid_250.csv', '1119-1in3out-mv-mc-mid_255.csv', '1119-1in3out-mv-mc-mid_260.csv', '1119-1in3out-mv-mc-mid_265.csv', '1119-1in3out-mv-mc-mid_270.csv', '1119-1in3out-mv-mc-mid_275.csv', '1119-1in3out-mv-mc-mid_280.csv', '1119-1in3out-mv-mc-mid_285.csv', '1119-1in3out-mv-mc-mid_290.csv', '1119-1in3out-mv-mc-mid_295.csv', '1119-1in3out-mv-mc-mid_300.csv', '1119-1in3out-mv-mc-mid_305.csv', '1119-1in3out-mv-mc-mid_310.csv', '1119-1in3out-mv-mc-mid_315.csv', '1119-1in3out-mv-mc-mid_320.csv']\n",
      "çµ„ 5: ['1119-1in3out-mv-mc-mid_325.csv', '1119-1in3out-mv-mc-mid_330.csv', '1119-1in3out-mv-mc-mid_335.csv', '1119-1in3out-mv-mc-mid_340.csv', '1119-1in3out-mv-mc-mid_345.csv', '1119-1in3out-mv-mc-mid_350.csv', '1119-1in3out-mv-mc-mid_355.csv', '1119-1in3out-mv-mc-mid_360.csv', '1119-1in3out-mv-mc-mid_365.csv', '1119-1in3out-mv-mc-mid_370.csv', '1119-1in3out-mv-mc-mid_375.csv', '1119-1in3out-mv-mc-mid_380.csv', '1119-1in3out-mv-mc-mid_385.csv', '1119-1in3out-mv-mc-mid_390.csv', '1119-1in3out-mv-mc-mid_395.csv', '1119-1in3out-mv-mc-mid_400.csv']\n",
      "Loading model: pretrain_videomae_base_patch1_4\n",
      "pretrain_videomae_base_patch1_4 is being executed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2535561/4187398625.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(model_path, map_location=\"cpu\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PretrainVisionTransformer(\n",
       "  (encoder): PretrainVisionTransformerEncoder(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv3d(1, 768, kernel_size=(2, 1, 1), stride=(2, 1, 1))\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0-11): 12 x Block(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (head): Identity()\n",
       "  )\n",
       "  (decoder): PretrainVisionTransformerDecoder(\n",
       "    (blocks): ModuleList(\n",
       "      (0-7): 8 x Block(\n",
       "        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=512, out_features=1536, bias=False)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "    (head): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       "  (encoder_to_decoder): Linear(in_features=768, out_features=512, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = CSVMAETEST(root_dir=csv_folder, num_frames=num_frames, mask_ratio=mask_ratio, window_size=window_size)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "print(f\"Loading model: {model_name}\")\n",
    "\n",
    "model = create_model(\n",
    "        model_name,\n",
    "        pretrained=False,\n",
    "        drop_path_rate=0,\n",
    "        drop_block_rate=None,\n",
    "        decoder_depth=decoder_depth,\n",
    "        use_checkpoint=model_path\n",
    "    )\n",
    "checkpoint = torch.load(model_path, map_location=\"cpu\")\n",
    "model.load_state_dict(checkpoint[\"model\"])\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_normalize(log_normalized_values):\n",
    "    # å°‡ 0~1 çš„æ­£è¦åŒ–æ•¸æ“šåè½‰å› log ç¯„åœï¼Œç„¶å¾Œå†è½‰å›ç·šæ€§ç©ºé–“çš„åŸå§‹ç¯„åœ\n",
    "    original_min = 300\n",
    "    original_max = 1600\n",
    "    log_values = log_normalized_values * (np.log(original_max) - np.log(original_min)) + np.log(original_min)\n",
    "    original_values = np.exp(log_values)\n",
    "    return original_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for video 0: 0.002899080514907837\n",
      "ğŸ” åŸå§‹ mask å½¢ç‹€: (128, 1)\n",
      "ğŸ” åŸå§‹ output å½¢ç‹€: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 1: 0.0044289506040513515\n",
      "ğŸ” åŸå§‹ mask å½¢ç‹€: (128, 1)\n",
      "ğŸ” åŸå§‹ output å½¢ç‹€: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 2: 0.0023416648618876934\n",
      "ğŸ” åŸå§‹ mask å½¢ç‹€: (128, 1)\n",
      "ğŸ” åŸå§‹ output å½¢ç‹€: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for video 3: 0.0020556622184813023\n",
      "ğŸ” åŸå§‹ mask å½¢ç‹€: (128, 1)\n",
      "ğŸ” åŸå§‹ output å½¢ç‹€: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 4: 0.0028789681382477283\n",
      "ğŸ” åŸå§‹ mask å½¢ç‹€: (128, 1)\n",
      "ğŸ” åŸå§‹ output å½¢ç‹€: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 5: 0.002318082842975855\n",
      "ğŸ” åŸå§‹ mask å½¢ç‹€: (128, 1)\n",
      "ğŸ” åŸå§‹ output å½¢ç‹€: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 6: 0.002188839018344879\n",
      "ğŸ” åŸå§‹ mask å½¢ç‹€: (128, 1)\n",
      "ğŸ” åŸå§‹ output å½¢ç‹€: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 7: 0.0032433411106467247\n",
      "ğŸ” åŸå§‹ mask å½¢ç‹€: (128, 1)\n",
      "ğŸ” åŸå§‹ output å½¢ç‹€: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for video 8: 0.0024422649294137955\n",
      "ğŸ” åŸå§‹ mask å½¢ç‹€: (128, 1)\n",
      "ğŸ” åŸå§‹ output å½¢ç‹€: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 9: 0.0014716566074639559\n",
      "ğŸ” åŸå§‹ mask å½¢ç‹€: (128, 1)\n",
      "ğŸ” åŸå§‹ output å½¢ç‹€: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 10: 0.0016057101311162114\n",
      "ğŸ” åŸå§‹ mask å½¢ç‹€: (128, 1)\n",
      "ğŸ” åŸå§‹ output å½¢ç‹€: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 11: 0.0010196678340435028\n",
      "ğŸ” åŸå§‹ mask å½¢ç‹€: (128, 1)\n",
      "ğŸ” åŸå§‹ output å½¢ç‹€: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 12: 0.0008419518126174808\n",
      "ğŸ” åŸå§‹ mask å½¢ç‹€: (128, 1)\n",
      "ğŸ” åŸå§‹ output å½¢ç‹€: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for video 13: 0.0004488519625738263\n",
      "ğŸ” åŸå§‹ mask å½¢ç‹€: (128, 1)\n",
      "ğŸ” åŸå§‹ output å½¢ç‹€: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 14: 0.00038490607403218746\n",
      "ğŸ” åŸå§‹ mask å½¢ç‹€: (128, 1)\n",
      "ğŸ” åŸå§‹ output å½¢ç‹€: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 15: 0.001671662088483572\n",
      "ğŸ” åŸå§‹ mask å½¢ç‹€: (128, 1)\n",
      "ğŸ” åŸå§‹ output å½¢ç‹€: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 16: 0.0014508028980344534\n",
      "ğŸ” åŸå§‹ mask å½¢ç‹€: (128, 1)\n",
      "ğŸ” åŸå§‹ output å½¢ç‹€: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 17: 0.0008252931875176728\n",
      "ğŸ” åŸå§‹ mask å½¢ç‹€: (128, 1)\n",
      "ğŸ” åŸå§‹ output å½¢ç‹€: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for video 18: 0.0018800904508680105\n",
      "ğŸ” åŸå§‹ mask å½¢ç‹€: (128, 1)\n",
      "ğŸ” åŸå§‹ output å½¢ç‹€: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 19: 0.0006583036156371236\n",
      "ğŸ” åŸå§‹ mask å½¢ç‹€: (128, 1)\n",
      "ğŸ” åŸå§‹ output å½¢ç‹€: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 20: 0.004521622322499752\n",
      "ğŸ” åŸå§‹ mask å½¢ç‹€: (128, 1)\n",
      "ğŸ” åŸå§‹ output å½¢ç‹€: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 21: 0.0026586195454001427\n",
      "ğŸ” åŸå§‹ mask å½¢ç‹€: (128, 1)\n",
      "ğŸ” åŸå§‹ output å½¢ç‹€: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 22: 0.0014308742247521877\n",
      "ğŸ” åŸå§‹ mask å½¢ç‹€: (128, 1)\n",
      "ğŸ” åŸå§‹ output å½¢ç‹€: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for video 23: 0.0025491099804639816\n",
      "ğŸ” åŸå§‹ mask å½¢ç‹€: (128, 1)\n",
      "ğŸ” åŸå§‹ output å½¢ç‹€: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 24: 0.0010373072000220418\n",
      "ğŸ” åŸå§‹ mask å½¢ç‹€: (128, 1)\n",
      "ğŸ” åŸå§‹ output å½¢ç‹€: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 25: 0.0009260214865207672\n",
      "ğŸ” åŸå§‹ mask å½¢ç‹€: (128, 1)\n",
      "ğŸ” åŸå§‹ output å½¢ç‹€: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 26: 0.0007329643703997135\n",
      "ğŸ” åŸå§‹ mask å½¢ç‹€: (128, 1)\n",
      "ğŸ” åŸå§‹ output å½¢ç‹€: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 27: 0.0012101843021810055\n",
      "ğŸ” åŸå§‹ mask å½¢ç‹€: (128, 1)\n",
      "ğŸ” åŸå§‹ output å½¢ç‹€: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for video 28: 0.0012758761877194047\n",
      "ğŸ” åŸå§‹ mask å½¢ç‹€: (128, 1)\n",
      "ğŸ” åŸå§‹ output å½¢ç‹€: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 29: 0.0033207666128873825\n",
      "ğŸ” åŸå§‹ mask å½¢ç‹€: (128, 1)\n",
      "ğŸ” åŸå§‹ output å½¢ç‹€: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 30: 0.0020950494799762964\n",
      "ğŸ” åŸå§‹ mask å½¢ç‹€: (128, 1)\n",
      "ğŸ” åŸå§‹ output å½¢ç‹€: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 31: 0.00226253317669034\n",
      "ğŸ” åŸå§‹ mask å½¢ç‹€: (128, 1)\n",
      "ğŸ” åŸå§‹ output å½¢ç‹€: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 32: 0.0007531484588980675\n",
      "ğŸ” åŸå§‹ mask å½¢ç‹€: (128, 1)\n",
      "ğŸ” åŸå§‹ output å½¢ç‹€: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for video 33: 0.0007104355609044433\n",
      "ğŸ” åŸå§‹ mask å½¢ç‹€: (128, 1)\n",
      "ğŸ” åŸå§‹ output å½¢ç‹€: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 34: 0.001528094056993723\n",
      "ğŸ” åŸå§‹ mask å½¢ç‹€: (128, 1)\n",
      "ğŸ” åŸå§‹ output å½¢ç‹€: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 35: 0.003332449123263359\n",
      "ğŸ” åŸå§‹ mask å½¢ç‹€: (128, 1)\n",
      "ğŸ” åŸå§‹ output å½¢ç‹€: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 36: 0.0029773046262562275\n",
      "ğŸ” åŸå§‹ mask å½¢ç‹€: (128, 1)\n",
      "ğŸ” åŸå§‹ output å½¢ç‹€: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 37: 0.0004075428587384522\n",
      "ğŸ” åŸå§‹ mask å½¢ç‹€: (128, 1)\n",
      "ğŸ” åŸå§‹ output å½¢ç‹€: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for video 38: 0.0006841092254035175\n",
      "ğŸ” åŸå§‹ mask å½¢ç‹€: (128, 1)\n",
      "ğŸ” åŸå§‹ output å½¢ç‹€: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 39: 0.0008136228425428271\n",
      "ğŸ” åŸå§‹ mask å½¢ç‹€: (128, 1)\n",
      "ğŸ” åŸå§‹ output å½¢ç‹€: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 40: 0.0005859936936758459\n",
      "ğŸ” åŸå§‹ mask å½¢ç‹€: (128, 1)\n",
      "ğŸ” åŸå§‹ output å½¢ç‹€: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 41: 0.0009556381264701486\n",
      "ğŸ” åŸå§‹ mask å½¢ç‹€: (128, 1)\n",
      "ğŸ” åŸå§‹ output å½¢ç‹€: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 42: 0.0013937163166701794\n",
      "ğŸ” åŸå§‹ mask å½¢ç‹€: (128, 1)\n",
      "ğŸ” åŸå§‹ output å½¢ç‹€: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "Loss for video 43: 0.0008542629657313228\n",
      "ğŸ” åŸå§‹ mask å½¢ç‹€: (128, 1)\n",
      "ğŸ” åŸå§‹ output å½¢ç‹€: (64, 2)\n",
      "(16, 8)\n",
      "(16, 16)\n",
      "(16, 16)\n",
      "âœ… æ‰€æœ‰çµæœå·²åˆä½µå„²å­˜è‡³ output_csv/final_output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "/home/zisheng/anaconda3/envs/videomae/lib/python3.8/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from einops import rearrange\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "final_df_list = []\n",
    "\n",
    "for idx, (videos, bool_masked_pos) in enumerate(dataloader):\n",
    "    videos = videos.to(device, non_blocking=True)\n",
    "    bool_masked_pos = bool_masked_pos.to(device, non_blocking=True).flatten(1).to(torch.bool)\n",
    "\n",
    "    # é€²è¡Œæ¨ç†\n",
    "    with torch.no_grad():\n",
    "        # Rearrange and process the frames\n",
    "        videos_patch = rearrange(videos, 'b c (t p0) (h p1) (w p2) -> b (t h w) (p0 p1 p2 c)',\n",
    "                                 p0=2, p1=patch_size, p2=patch_size)\n",
    "        B, _, C = videos_patch.shape\n",
    "\n",
    "        labels = videos_patch[bool_masked_pos].reshape(B, -1, C)\n",
    "        outputs = model(videos, bool_masked_pos)\n",
    "        loss = loss_func(input=outputs, target=labels)\n",
    "        print(f\"Loss for video {idx}: {loss.item()}\")\n",
    "\n",
    "    # è½‰æ›ç‚º NumPy æ ¼å¼\n",
    "    outputs_np = outputs.cpu().detach().numpy().reshape(-1, 2)  # (N_mask, C)\n",
    "    mask_np = bool_masked_pos.cpu().detach().numpy().reshape(-1).astype(int)  # (N,)\n",
    "\n",
    "    # âœ… **å³æ™‚å„²å­˜çµæœ**ï¼ˆåŸæœ¬çš„æ–¹å¼ï¼‰\n",
    "    output_list = [outputs_np]\n",
    "    mask_list = [mask_np]\n",
    "\n",
    "    df_outputs = pd.DataFrame(np.concatenate(output_list, axis=0))  # (N, C)\n",
    "    df_masks = pd.DataFrame(np.concatenate(mask_list, axis=0))  # (N,)\n",
    "\n",
    "    print(\"ğŸ” åŸå§‹ mask å½¢ç‹€:\", df_masks.shape)\n",
    "    print(\"ğŸ” åŸå§‹ output å½¢ç‹€:\", df_outputs.shape)\n",
    "\n",
    "    # **é‚„åŸå®Œæ•´çš„æ„Ÿæ¸¬å™¨æ•¸æ“š**\n",
    "    sensor_data = videos.cpu().detach().numpy().squeeze(0)  # (C=1, T, H, W) â†’ (T, H, W)\n",
    "    sensor_data = sensor_data.reshape(num_frames, -1)  # è½‰æ›ç‚º (T, sensors)\n",
    "    # ä¿ç•™ä¸€ä»½åŸå§‹æ„Ÿæ¸¬å™¨æ•¸æ“šï¼ˆåæ­£è¦åŒ–å‰ï¼‰\n",
    "    sensor_data_ori = sensor_data.copy()\n",
    "    sensor_data_ori = inverse_normalize(sensor_data_ori)\n",
    "\n",
    "    # **mask=1 çš„åœ°æ–¹ç”¨ `df_outputs` é æ¸¬å€¼æ›¿æ›**\n",
    "    predicted_values = df_outputs.to_numpy().reshape(num_frames, -1)  # (T, é æ¸¬çš„ sensor å€¼)\n",
    "    mask_reshaped = df_masks.to_numpy().reshape(-1, num_frames)  # (H Ã— W, T) â†’ (T, H Ã— W)\n",
    "    mask_reshaped = np.tile(mask_reshaped, (2, 1))\n",
    "\n",
    "    print(predicted_values.shape)\n",
    "    print(sensor_data.shape)\n",
    "    print(mask_reshaped.shape)\n",
    "\n",
    "    predicted_values_padded = np.zeros_like(sensor_data)\n",
    "    predicted_values_padded[mask_reshaped == 1] = predicted_values.flatten()\n",
    "    sensor_data[mask_reshaped == 1] = predicted_values_padded[mask_reshaped == 1]\n",
    "    sensor_data = inverse_normalize(sensor_data)\n",
    "\n",
    "    # å…ˆå»ºç«‹ DataFrameï¼Œåªæœ‰ sensor_dataï¼ˆä¿®æ”¹å¾Œï¼‰\n",
    "    final_df = pd.DataFrame(sensor_data)\n",
    "    sensor_columns = [f\"sensor{i+1}\" for i in range(sensor_data.shape[1])]\n",
    "    final_df.columns = sensor_columns\n",
    "    # â”€â”€ æ–°å¢ï¼šå»ºç«‹åŸå§‹æ„Ÿæ¸¬å™¨æ•¸æ“šçš„ DataFrame â”€â”€\n",
    "    ori_sensor_df = pd.DataFrame(sensor_data_ori, columns=[f\"origin_{i+1}\" for i in range(sensor_data_ori.shape[1])])\n",
    "    # â”€â”€ æ–°å¢ï¼šè¨ˆç®—ç›¸å°èª¤å·®ï¼ˆåƒ…é‡å° mask æ‰çš„æ„Ÿæ¸¬å™¨ï¼‰ â”€â”€\n",
    "    # ç›¸å°èª¤å·® = abs(ä¿®æ”¹å¾Œ - åŸå§‹) / abs(åŸå§‹)\n",
    "    rel_error = np.abs(sensor_data - sensor_data_ori) / np.abs(sensor_data_ori)\n",
    "    # åªä¿ç•™ mask å€åŸŸçš„èª¤å·®ï¼Œå…¶ä»–è¨­å®šç‚º NaN\n",
    "    rel_error[mask_reshaped != 1] = np.nan\n",
    "    # å»ºç«‹ç›¸å°èª¤å·®çš„ DataFrameï¼Œæ¬„ä½å‘½åç‚º mask_1, mask_2, ..., mask_n\n",
    "    rel_error_df = pd.DataFrame(rel_error, columns=[f\"mask_{i+1}\" for i in range(sensor_data.shape[1])])\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "    # â”€â”€ æ–°å¢ï¼šè¨ˆç®—æ¯å€‹æ™‚é–“æ­¥ï¼ˆè¡Œï¼‰çš„å¹³å‡ç›¸å°èª¤å·®ï¼ˆå¿½ç•¥ NaNï¼‰ï¼Œæ–°å¢æ¬„ä½ \"average\" â”€â”€\n",
    "    average_error = rel_error_df.mean(axis=1, skipna=True)\n",
    "    average_error_df = pd.DataFrame(average_error, columns=[\"average\"])\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "    # â”€â”€ æ–°å¢ï¼šè¨ˆç®—æ¯å€‹æ™‚é–“æ­¥ï¼ˆè¡Œï¼‰ä¸­ï¼Œmask_{ç·¨è™Ÿ} æ¬„ä½çš„æœ€å¤§å€¼ï¼Œæ–°å¢æ¬„ä½ \"max\" â”€â”€\n",
    "    max_error = rel_error_df.max(axis=1, skipna=True)\n",
    "    max_error_df = pd.DataFrame(max_error, columns=[\"max\"])\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "    # åˆä½µä¿®æ”¹å¾Œçš„æ„Ÿæ¸¬å™¨æ•¸æ“šã€åŸå§‹æ„Ÿæ¸¬å™¨æ•¸æ“šã€ç›¸å°èª¤å·®ã€å¹³å‡ç›¸å°èª¤å·®èˆ‡æœ€å¤§èª¤å·®ï¼ˆæ©«å‘åˆä½µï¼‰\n",
    "    final_df = pd.concat([final_df, ori_sensor_df, rel_error_df, average_error_df, max_error_df], axis=1)\n",
    "    final_df_list.append(final_df)\n",
    "\n",
    "# åˆä½µæ‰€æœ‰ video çš„ DataFrame æˆä¸€å€‹ DataFrameï¼Œä¸¦å„²å­˜åˆ°åŒä¸€å€‹ CSV æª”æ¡ˆä¸­\n",
    "all_final_df = pd.concat(final_df_list, axis=0, ignore_index=True)\n",
    "all_final_df.to_csv(f\"{save_path}/final_output.csv\", index=False)\n",
    "\n",
    "print(f\"âœ… æ‰€æœ‰çµæœå·²åˆä½µå„²å­˜è‡³ {save_path}/final_output.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from timm.models import create_model\n",
    "from utils import NativeScalerWithGradNormCount as NativeScaler\n",
    "import utils\n",
    "from datasets import CSVMAE\n",
    "from einops import rearrange\n",
    "\n",
    "def load_model(model_name, weights_path, device):\n",
    "    print(f\"Loading model: {model_name}\")\n",
    "    model = create_model(\n",
    "        model_name,\n",
    "        pretrained=False,\n",
    "        drop_path_rate=0.0,\n",
    "        drop_block_rate=None,\n",
    "        decoder_depth=4,\n",
    "        use_checkpoint=False\n",
    "    )\n",
    "    checkpoint = torch.load(weights_path, map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['model'], strict=False)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def validate(model, dataloader, device, output_file):\n",
    "    loss_func = torch.nn.MSELoss()\n",
    "    results = []\n",
    "    total_loss = 0.0\n",
    "    num_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for step, (videos, bool_masked_pos) in enumerate(dataloader):\n",
    "\n",
    "            videos = videos.to(device, non_blocking=True)\n",
    "            bool_masked_pos = bool_masked_pos.to(device, non_blocking=True).flatten(1).to(torch.bool)\n",
    "            \n",
    "            videos_patch = rearrange(videos, 'b c (t p0) (h p1) (w p2) -> b (t h w) (p0 p1 p2 c)', p0=2, p1=1, p2=1)\n",
    "            B, _, C = videos_patch.shape\n",
    "            labels = videos_patch[bool_masked_pos].reshape(B, -1, C)\n",
    "            outputs = model(videos, bool_masked_pos)\n",
    "            # **è¨ˆç®— Loss**\n",
    "            loss = loss_func(outputs, labels)\n",
    "            loss_value = loss.item()\n",
    "            total_loss += loss_value\n",
    "            num_samples += 1\n",
    "\n",
    "            print(f\"Step {step + 1}/{len(dataloader)} - Loss: {loss_value:.6f}\")\n",
    "\n",
    "    # è¨ˆç®—å¹³å‡ Loss\n",
    "    avg_loss = total_loss / num_samples if num_samples > 0 else float('nan')\n",
    "    print(f\"âœ… å¹³å‡ Loss: {avg_loss:.6f}\")\n",
    "\n",
    "    # **å„²å­˜çµæœ**\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write(f\"Average Loss: {avg_loss:.6f}\\n\")\n",
    "        for res in results:\n",
    "            f.write(str(res) + '\\n')\n",
    "\n",
    "    print(f\"Validation results and loss saved to {output_file}\")\n",
    "\n",
    "\n",
    "def run_validation(model_name, weights_path, data_path, batch_size, device, output_file):\n",
    "    if not os.path.exists(data_path):\n",
    "        print(\"Error: Data path does not exist!\")\n",
    "        return\n",
    "    \n",
    "    model = load_model(model_name, weights_path, device)\n",
    "    patch_size = model.encoder.patch_embed.patch_size\n",
    "    window_size = (16 // 2, 4 // patch_size[0], 4 // patch_size[1])\n",
    "    dataset = CSVMAE(root_dir=data_path, num_frames=16, window_size=window_size)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, num_workers=4, pin_memory=True)\n",
    "    validate(model, dataloader, device, output_file)\n",
    "\n",
    "model_name = 'pretrain_videomae_base_patch1_4'\n",
    "weights_path = '/mnt/d/haoxiangbiya/VideoMAE/ckpt_output_dir/checkpoint-2499.pth'\n",
    "data_path = '/mnt/d/mae/bigclassroom/foundation_dataset/train'\n",
    "batch_size = 8\n",
    "device = 'cuda'\n",
    "output_file = 'validation_results.txt'\n",
    "\n",
    "run_validation(model_name, weights_path, data_path, batch_size, device, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from masking_generator import TubeMaskingGenerator  # å‡è¨­ä½ æœ‰é€™å€‹maskç”Ÿæˆå™¨\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "class CustomCSVMAE(Dataset):\n",
    "    def __init__(self, root_dir, num_frames=16, mask_ratio=0.75, patch_size=16, window_size=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.num_frames = num_frames\n",
    "        self.mask_ratio = mask_ratio\n",
    "        self.patch_size = patch_size\n",
    "        self.mask_generator = TubeMaskingGenerator(window_size, mask_ratio=mask_ratio)\n",
    "\n",
    "        # éè¿´åœ°ç²å–æ‰€æœ‰ CSV æª”æ¡ˆ\n",
    "        self.file_paths = []\n",
    "        for subdir, _, files in os.walk(root_dir):\n",
    "            for file in files:\n",
    "                if file.endswith('.csv'):\n",
    "                    self.file_paths.append(os.path.join(subdir, file))\n",
    "\n",
    "        # è‡ªè¨‚æ’åºå‡½æ•¸ï¼šæŒ‰æª”æ¡ˆåä¸­çš„æ•¸å­—æ™‚é–“æˆ³æ’åº\n",
    "        def extract_sort_key(path):\n",
    "            filename = os.path.basename(path)\n",
    "            match = re.match(r\"(.+?)_(\\d+)\\.csv\", filename)  # æ“·å–é¡åˆ¥åç¨± & æ•¸å­—\n",
    "            if match:\n",
    "                category = match.group(1)  # å–å¾—é¡åˆ¥åç¨± (å¦‚ 1119-1in3out-mv-mc-mid)\n",
    "                time_value = int(match.group(2))  # å–å¾—æ•¸å­—æ™‚é–“æˆ³\n",
    "                return (category, time_value)\n",
    "            return (filename, 0)  # è‹¥ç„¡æ³•åŒ¹é…å‰‡æ”¾æœ€å¾Œ\n",
    "\n",
    "        # æ’åºå¾ŒæŒ‰é¡åˆ¥åˆ†çµ„\n",
    "        self.file_paths.sort(key=extract_sort_key)\n",
    "        self.groups = defaultdict(list)  # æ¯å€‹é¡åˆ¥å°æ‡‰çš„ CSV æª”æ¡ˆ\n",
    "        for path in self.file_paths:\n",
    "            category = extract_sort_key(path)[0]  # å–å¾—é¡åˆ¥åç¨±\n",
    "            self.groups[category].append(path)\n",
    "\n",
    "        # æŒ‰ç…§ num_frames åˆ‡å‰²æˆæ™‚é–“æ®µ\n",
    "        self.sequence_groups = []\n",
    "        for category, files in self.groups.items():\n",
    "            if len(files) >= num_frames:\n",
    "                for i in range(len(files) - num_frames + 1):\n",
    "                    self.sequence_groups.append(files[i: i + num_frames])\n",
    "\n",
    "        if not self.sequence_groups:\n",
    "            raise ValueError(f\"CSV æª”æ¡ˆæ•¸é‡ä¸è¶³ {num_frames}ï¼Œè«‹æª¢æŸ¥ `{root_dir}` è³‡æ–™å¤¾ï¼\")\n",
    "\n",
    "        # é¡¯ç¤ºå‰ 5 çµ„æ•¸æ“š\n",
    "        print(\"= åŠ è¼‰çš„ CSV æ™‚é–“åºåˆ—çµ„: (é¡¯ç¤ºå‰ 5 çµ„) =\")\n",
    "        for i, seq in enumerate(self.sequence_groups[:5]):\n",
    "            print(f\"çµ„ {i+1}: {[os.path.basename(f) for f in seq]}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequence_groups)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_list = self.sequence_groups[idx]  # å–å¾—å°æ‡‰çš„ä¸€çµ„ num_frames CSV æª”æ¡ˆ\n",
    "        frames = []\n",
    "        bool_masked_pos = []  # ç”¨ä¾†å„²å­˜æ¯å€‹ frame çš„ mask è¨Šæ¯\n",
    "\n",
    "        # è®€å–æ¯å€‹å½±ç‰‡çš„ frames å’Œå°æ‡‰çš„ mask\n",
    "        for csv_path in file_list:\n",
    "            data = np.genfromtxt(csv_path, delimiter=',')\n",
    "            frames.append(data)\n",
    "\n",
    "            # ç”Ÿæˆ maskï¼Œé€™éƒ¨åˆ†å¯ä»¥ä½¿ç”¨æ‚¨å…ˆå‰çš„ `TubeMaskingGenerator`\n",
    "            mask = np.random.binomial(1, self.mask_ratio, data.shape)  # éš¨æ©Ÿç”Ÿæˆçš„ mask\n",
    "            bool_masked_pos.append(mask)\n",
    "\n",
    "        frames = np.stack(frames)  # (T, H, W)\n",
    "        frames = np.expand_dims(frames, axis=0)  # å¢åŠ  Channel ç¶­åº¦ (C=1, T, H, W)\n",
    "        frames = torch.tensor(frames, dtype=torch.float32)\n",
    "\n",
    "        bool_masked_pos = np.stack(bool_masked_pos)  # (T, H, W)\n",
    "        bool_masked_pos = torch.tensor(bool_masked_pos, dtype=torch.bool)\n",
    "\n",
    "        return (frames, bool_masked_pos)\n",
    "\n",
    "# ä½¿ç”¨ç¤ºä¾‹ï¼š\n",
    "csv_folder = \"/path/to/your/csv/folder\"\n",
    "dataset = CustomCSVMAE(root_dir=csv_folder, num_frames=16, mask_ratio=0.75, patch_size=16)\n",
    "\n",
    "# æ‰“å°æŸä¸€çµ„è³‡æ–™ï¼Œæª¢æŸ¥è³‡æ–™æ˜¯å¦æ­£ç¢º\n",
    "sample_frames, sample_mask = dataset[0]  # é¡¯ç¤ºç¬¬ä¸€çµ„è³‡æ–™\n",
    "print(\"Sample Frames Shape:\", sample_frames.shape)\n",
    "print(\"Sample Mask Shape:\", sample_mask.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "videomae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
